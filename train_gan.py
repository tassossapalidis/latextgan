import tensorflow as tf
import numpy as np
from gan import Generator, Discriminator
## ALSO NEED AUTOENCODER MODEL
## since this model will be pre-trained, we need to load the weights in
## possibly just pass path to model.save() file

'''
assumptions:
- we have a working generator and discriminator
- generator takes a latent vector and outputs a context vector of 
  dimension equal to the context vectors generated by the autoencoder
- discriminator takes a context vector and outputs real number in (0 (fake), 1 (real))

- args: units -- size of hidden context vector (and, for now, also dimension of 
                 latent z being fed into generator)
        batch_size
        n_generator_train -- how frequently to train the generator
        epochs -- number of epochs to train for
'''

# call constructors
encoder = Encoder(args.units...)
decoder = Decoder(args.units...)
generator = ...
discriminator = ..

# make a checkpoint and restore autoencoder weights
## this might have to be saved_model; not sure
checkpoint.restore_from_checkpoint(...)

# real_data shape == fake_data shape (batch_size, units)
# TODO: check these shapes and this formula
def grad_penalty(real_data, fake_data):
    alpha = tf.random.uniform(shape = (BATCH_SIZE, 1), minval = 0, maxval = 1)
    vect = alpha*real_data + (1-alpha)*fake_data
    with tf.GradientTape() as tape:
        # prediction shape: (batch_size, 1)
        tape.watch(vect)
        prediction = discriminator(vect)
    # gradients shape: (batch_size, num_variables) ?
    gradients = tape.gradient(prediction, vect)
    grad_norm = tf.linalg.norm(gradients, axis = 1)
    return tf.reduce_mean((grad_norm - 1)**2)

def discriminator_loss(real_pred, fake_pred):
    ## Wasserstein loss -- no log here
    return -tf.mean(real_pred) + tf.mean(fake_pred)

def generator_loss(fake_pred):
    return -tf.mean(fake_pred)

def train_step_disc(real_data_batch):
    disc_loss = 0
    with tf.GradientTape() as tape:
        z = tf.random.normal((args.batch_size, args.units))
        real_vects = encoder(real_data_batch)
        ## real_vects shape: (batch_size, units)
        
        # discriminator for wgan actually predicts "level of realness" of image
        real_predictions = discriminator(real_vects)
        fake_predictions = discriminator(generator(z))
        disc_loss = discriminator_loss(real_predictions, fake_predictions)
        variables = discriminator.trainable_variables
    gradients = tape.gradient(disc_loss, variables)
    optimizer.apply_gradients(zip(gradients, variables))
        
    return disc_loss


def train_step_gen():
    gen_loss = 0 
    with tf.GradientTape() as tape:
        z = tf.random.normal((args.batch_size, args.units))
        fake_predictions = discriminator(generator(z))
        gen_loss = generator_loss(fake_predictions)

        variables = generator.trainable_variables)
    gradients = tape.gradient(gen_loss, variables)
    optimizer.apply_gradients(zip(gradients, variables))

    return gen_loss

def main():
    optimizer = tf.keras.optimizers.Adam()
    for epoch in range(EPOCHS):
        disc_loss = 0
        for (i, x) in enumerate(data):
            disc_loss += train_step_disc(real_data_batch)
        disc_loss /= i

        if (epoch % n_generator_train) == 0:
            gen_loss = 0

            # change this. don't actually need data but just want to make sure
            # generator is getting same number of updates as discriminator.
            # also not totally sure if this is the right thing to do 
            for i, _ in enumerate(data):
                gen_loss += train_step_gen()
            gen_loss /= i
